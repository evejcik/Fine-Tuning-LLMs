{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU is available!\")\n",
    "else:\n",
    "    print(\"GPU not detected. Check your CUDA installation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import bz2\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW, get_scheduler, TrainingArguments, Trainer, EarlyStoppingCallback, TrainerCallback\n",
    "from huggingface_hub.inference_api import InferenceApi\n",
    "from datasets import load_dataset, Dataset\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import sqlite3 \n",
    "from sklearn.model_selection import train_test_split\n",
    "import optuna\n",
    "\n",
    "\n",
    "from customhead import CustomClassificationHead\n",
    "import tensorboardX\n",
    "import gc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hugging face access token: \n",
    "# API_TOKEN = \"\"\n",
    "# os.environ[\"HF_TOKEN\"] = \"\"\n",
    "\n",
    "#huggingface-cli login ****Edit -> paste**** (not CTRL+V)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference = InferenceApi(repo_id=\"bert-base-uncased\", token=API_TOKEN)\n",
    "# response = inference(inputs=\"The goal of life is [MASK].\", raw_response =True)\n",
    "# print(response.json())\n",
    "# Load the Gemini tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"describeai/gemini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# print(os.path.getsize('IMDB_Movies_2021.db'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connection = sqlite3.connect('IMDB_Movies_2021.db') \n",
    "# tables = pd.read_sql_query(\"SELECT name FROM sqlite_master WHERE type='table';\", connection)\n",
    "# print(tables)\n",
    "\n",
    "# query = \"SELECT * FROM REVIEWS\"\n",
    "# df = pd.read_sql_query(query, connection)\n",
    "\n",
    "# connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data loading block\n",
    "\n",
    "df = pd.read_csv(\"movies.csv\")\n",
    "\n",
    "df = df.dropna()\n",
    "\n",
    "\n",
    "df.head()\n",
    "# df.to_csv('movies.csv', index = False)\n",
    "\n",
    "# df.shape #5450, 5\n",
    "\n",
    "df['labels'] =df['RATING'].astype(int) -1\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(df['RATING'][1])\n",
    "# df['RATING'].isnull().sum()\n",
    "\n",
    "# df['labels'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "# train_df, val_df = train_test_split(train_df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def sample_data(df, num_samples, classes_to_keep):\n",
    "#     # Sample rows, selecting num_samples of each Label.                                      \n",
    "#     df = (\n",
    "#         df.groupby(\"Label\")[df.columns]\n",
    "#         .apply(lambda x: x.sample(num_samples))\n",
    "#         .reset_index(drop=True)\n",
    "#     )\n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization function\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples['REVIEW'], truncation=True, padding='max_length', max_length=512) #512 helps keep memory cost down for GPU\n",
    "\n",
    "# Apply tokenization\n",
    "tokenized_dataset = dataset.map(preprocess_function, batched=True)\n",
    "# tokenized_dataset['label'][:1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_dataset = tokenized_dataset.train_test_split(test_size=0.2)\n",
    "\n",
    "test_valid_split = split_dataset['test'].train_test_split(test_size=0.5)\n",
    "\n",
    "tokenized_dataset_dict = {\n",
    "    'train': split_dataset['train'],\n",
    "    'validation': test_valid_split['train'],\n",
    "    'test': test_valid_split['test']\n",
    "}\n",
    "\n",
    "# print(tokenized_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # import torchvision\n",
    "# # print(\"Version:\", torchvision.__version__)\n",
    "# # print(\"Location:\", torchvision.__file__)\n",
    "\n",
    "# import numpy as np\n",
    "\n",
    "# labels_train = np.array([example[\"labels\"] for example in tokenized_dataset_dict[\"train\"]])\n",
    "# print(\"Min label:\", labels_train.min())\n",
    "# print(\"Max label:\", labels_train.max())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class EpochAccuracyLoggerCallback(TrainerCallback):\n",
    "    def on_epoch_end(self, args, state, control, metrics=None, **kwargs):\n",
    "        # Retrieve the current epoch (could be fractional)\n",
    "        epoch = state.epoch  \n",
    "        # Extract evaluation metrics, e.g., eval_accuracy and eval_loss if available\n",
    "        eval_accuracy = metrics.get(\"eval_accuracy\", None) if metrics else None\n",
    "        eval_loss = metrics.get(\"eval_loss\", None) if metrics else None\n",
    "\n",
    "        # You might also want to log which trial this is.\n",
    "        # If you're using hyperparameter search, trial information might not be directly available here.\n",
    "        # One approach is to include hyperparameter information in the logs via the Trainer's state if desired.\n",
    "        log_line = f\"Epoch {epoch:.2f}: Accuracy = {eval_accuracy}, Loss = {eval_loss}\\n\"\n",
    "        with open(\"epoch_metrics.txt\", \"a\") as f:\n",
    "            f.write(log_line)\n",
    "        return control\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Memory allocated:\", torch.cuda.memory_allocated())\n",
    "print(\"Memory reserved:\", torch.cuda.memory_reserved())\n",
    "\n",
    "\n",
    "# Suggest hyperparameters\n",
    "encoder_model = \"describeai/gemini\"\n",
    "# pct_finetune = trial.suggest_float(\"pct_finetune\", 0.0, 0.01, 0.1, 0.5 1.0)\n",
    "\n",
    "# If trial is None, use default hyperparameter values\n",
    "pct_finetune = 0.1\n",
    "hidden_size = 512\n",
    "num_hidden_layers = 2\n",
    "# pct_finetune = trial.suggest_categorical(\"pct_finetune\", [0.0, 0.01, 0.1, 0.5, 1.0])\n",
    "# \n",
    "\n",
    "\n",
    "# Load the base model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(encoder_model, num_labels=10)\n",
    "\n",
    "# Set the problem type (if not already set)\n",
    "model.config.problem_type = \"single_label_classification\"\n",
    "\n",
    "# Customize dropout if desired\n",
    "model.config.hidden_dropout_prob = 0.1\n",
    "model.config.attention_probs_dropout_prob = 0.1\n",
    "\n",
    "model.gradient_checkpointing_enable()\n",
    "\n",
    "if hasattr(model, \"encoder\"):\n",
    "    print(model.encoder)\n",
    "\n",
    "\n",
    "# Freeze a percentage of the encoder layers\n",
    "# (Assuming your model has an attribute 'encoder' with layers in model.encoder.block)\n",
    "try:\n",
    "    total_layers = len(model.encoder.block)\n",
    "    num_layers_to_freeze = int(total_layers * (1 - pct_finetune))\n",
    "    for i, layer in enumerate(model.encoder.block):\n",
    "        if i < num_layers_to_freeze:\n",
    "            for param in layer.parameters():\n",
    "                param.requires_grad = False\n",
    "except AttributeError:\n",
    "    print(\"Model does not have an encoder.block attribute\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_LABELS = 10\n",
    "\n",
    "def model_init(trial=None):\n",
    "\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    print(\"Before model init:\")\n",
    "    print(\"Memory allocated:\", torch.cuda.memory_allocated())\n",
    "    print(\"Memory reserved:\", torch.cuda.memory_reserved())\n",
    "\n",
    "\n",
    "    # Suggest hyperparameters\n",
    "    encoder_model = \"describeai/gemini\"\n",
    "    # pct_finetune = trial.suggest_float(\"pct_finetune\", 0.0, 0.01, 0.1, 0.5 1.0)\n",
    "\n",
    "    # If trial is None, use default hyperparameter values\n",
    "    if trial is None:\n",
    "        pct_finetune = 0.1\n",
    "        hidden_size = 512\n",
    "        num_hidden_layers = 2\n",
    "    else:\n",
    "        pct_finetune = trial.suggest_categorical(\"pct_finetune\", [0.0, 0.1, 0.5, 1.0])\n",
    "        hidden_size = trial.suggest_categorical(\"hidden_size\", [256, 512, 1024])\n",
    "        num_hidden_layers = trial.suggest_int(\"num_hidden_layers\", 1, 3)\n",
    "    # pct_finetune = trial.suggest_categorical(\"pct_finetune\", [0.0, 0.01, 0.1, 0.5, 1.0])\n",
    "    # \n",
    "\n",
    "    \n",
    "    \n",
    "    # Load the base model\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(encoder_model, num_labels=NUM_LABELS)\n",
    "    \n",
    "    # Set the problem type (if not already set)\n",
    "    model.config.problem_type = \"single_label_classification\"\n",
    "    \n",
    "    # Customize dropout if desired\n",
    "    model.config.hidden_dropout_prob = 0.1\n",
    "    model.config.attention_probs_dropout_prob = 0.1\n",
    "\n",
    "    model.gradient_checkpointing_enable()\n",
    "\n",
    "    if hasattr(model, \"encoder\"):\n",
    "        print(model.encoder)\n",
    "\n",
    "\n",
    "    # Freeze a percentage of the encoder layers\n",
    "\n",
    "    # Collect all parameters not in the classification head\n",
    "    non_head_params = [(name, param) for name, param in model.named_parameters() if \"classification_head\" not in name]\n",
    "\n",
    "    num_total = len(non_head_params)\n",
    "    # Calculate how many parameters to freeze: \n",
    "    # For example, if pct_finetune=0.1, then freeze 90% of non-head parameters.\n",
    "    num_to_freeze = int(num_total * (1 - pct_finetune))\n",
    "\n",
    "    print(f\"Total non-head parameters: {num_total}\")\n",
    "    print(f\"Freezing {num_to_freeze} parameters out of {num_total}\")\n",
    "\n",
    "    # Freeze the first 'num_to_freeze' parameters in the list\n",
    "    for name, param in non_head_params[:num_to_freeze]:\n",
    "        param.requires_grad = False\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "####################################################################################################################################################################################################################\n",
    "\n",
    "    # Customize classifier head if needed:\n",
    "    # If you want to add extra hidden layers or adjust the hidden size,\n",
    "    # you might need to replace the default classification head with your own.\n",
    "    # For example (this is pseudo-code):\n",
    "    #\n",
    "    # from my_custom_heads import CustomClassificationHead\n",
    "\n",
    "    # hidden_size = 512          # Example hidden size; try 256, 512, or 1024\n",
    "    # hidden_size = trial.suggest_categorical(\"hidden_size\", [256, 512, 1024])\n",
    "    # num_hidden_layers = 2      # Number of hidden layers in the head\n",
    "    # num_hidden_layers = trial.suggest_int(\"num_hidden_layers\", 1, 3)\n",
    "    num_labels = model.config.num_labels\n",
    "\n",
    "    model.classification_head = CustomClassificationHead(\n",
    "        input_dim=model.config.d_model, \n",
    "        num_hidden_layers=num_hidden_layers,\n",
    "        hidden_size=hidden_size,\n",
    "        num_labels=NUM_LABELS,\n",
    "    )\n",
    "    #\n",
    "    # For now, we'll assume you're using the default head.\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "####################################################################################################################################################################################################################\n",
    "\n",
    "def logging_callback(study, trial):\n",
    "    print(f\"Trial {trial.number} finished with value: {trial.value}\")\n",
    "    with open(\"trial_log.txt\", \"a\") as f:\n",
    "        f.write(f\"Trial {trial.number}: {trial.params}, Value: {trial.value}\\n\")\n",
    "    # Clear GPU cache after each trial\n",
    "    torch.cuda.empty_cache()\n",
    "    print(\"After trial {}:\".format(trial.number))\n",
    "    print(\"Memory allocated:\", torch.cuda.memory_allocated())\n",
    "    print(\"Memory reserved:\", torch.cuda.memory_reserved())\n",
    "\n",
    "####################################################################################################################################################################################################################\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy = \"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=4,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    save_total_limit=2,\n",
    "    fp16=False,\n",
    "    dataloader_num_workers=3,\n",
    "    report_to=[\"tensorboard\"],\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",  # Monitor \"accuracy\" for early stopping\n",
    "    greater_is_better=True\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model_init=model_init,  # This function will be used to initialize a new model for each trial\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset_dict[\"train\"],\n",
    "    eval_dataset=tokenized_dataset_dict[\"validation\"],\n",
    "    compute_metrics=lambda p: {\"accuracy\": (p.predictions.argmax(axis=-1) == p.label_ids).mean(),\n",
    "                                 \"eval_loss\": p.metrics.get(\"loss\") if hasattr(p, \"metrics\") else None},\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2), EpochAccuracyLoggerCallback()]\n",
    ")\n",
    "\n",
    "# Run hyperparameter search using Optuna\n",
    "best_trial = trainer.hyperparameter_search(\n",
    "    backend=\"optuna\",\n",
    "    n_trials=10,\n",
    "    direction=\"maximize\"\n",
    ")\n",
    "\n",
    "print(\"Best trial:\", best_trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the pre-trained Gemini model\n",
    "# model = AutoModelForSequenceClassification.from_pretrained(\"describeai/gemini\", num_labels=10) #2 labels since only doing binary classification here, match to num labels for multi-class classification\n",
    "\n",
    "# model.config.problem_type = \"single_label_classification\"\n",
    "\n",
    "# # Customize the configuration\n",
    "# model.config.hidden_dropout_prob = 0.1  # Reduce overfitting\n",
    "# model.config.attention_probs_dropout_prob = 0.1\n",
    "\n",
    "# print(model.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(model.classification_head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for name, param in model.named_parameters():\n",
    "#     if \"classification_head\" in name:\n",
    "#         print(name, param.shape)\n",
    "# # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Freeze all parameters first\n",
    "# for param in model.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "# # Unfreeze the classification head (if needed)\n",
    "# for name, param in model.classification_head.named_parameters():\n",
    "#     param.requires_grad = True\n",
    "\n",
    "# # Unfreeze the last 2 encoder blocks (example: if the encoder blocks are named \"encoder.block.X\")\n",
    "# # Adjust the key name pattern based on your model's naming convention\n",
    "# for name, param in model.named_parameters():\n",
    "#     if \"encoder.block\" in name:\n",
    "#         # Extract block number if available (this depends on the naming convention)\n",
    "#         block_number = int(name.split(\"encoder.block.\")[1].split(\".\")[0])\n",
    "#         if block_number >= (model.config.num_layers - 2):  # unfreeze the last 2 blocks\n",
    "#             param.requires_grad = True\n",
    "\n",
    "# # Check which parameters will be updated\n",
    "# trainable_params = [name for name, param in model.named_parameters() if param.requires_grad]\n",
    "# print(\"Trainable parameters:\", trainable_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # Optimizer\n",
    "# optimizer = AdamW(model.parameters(), lr=1e-5, weight_decay=0.01)\n",
    "\n",
    "# train_dataloader = DataLoader(split_dataset['train'], shuffle=True, batch_size=16)\n",
    "# num_epochs = 3\n",
    "\n",
    "# # Learning rate scheduler\n",
    "# num_training_steps = len(train_dataloader) * num_epochs\n",
    "# lr_scheduler = get_scheduler(\n",
    "#     \"linear\", optimizer=optimizer, num_warmup_steps=500, num_training_steps=num_training_steps\n",
    "# )\n",
    "\n",
    "# print(f\"Total training steps: {num_training_steps}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # split_dataset = tokenized_dataset.train_test_split(test_size=0.2)\n",
    "\n",
    "# # test_valid_split = split_dataset['test'].train_test_split(test_size=0.5)\n",
    "\n",
    "# # tokenized_dataset_dict = {\n",
    "# #     'train': split_dataset['train'],\n",
    "# #     'validation': test_valid_split['train'],\n",
    "# #     'test': test_valid_split['test']\n",
    "# # }\n",
    "\n",
    "# # def convert_labels(example):\n",
    "# #     # Adjust this mapping based on your actual label names\n",
    "# #     mapping = {\"__label__2\": 0, \"__label__1\": 1}\n",
    "# #     example[\"label\"] = mapping[example[\"label\"]]\n",
    "# #     return example\n",
    "\n",
    "# # tokenized_dataset_dict[\"train\"] = tokenized_dataset_dict[\"train\"].map(convert_labels)\n",
    "# # tokenized_dataset_dict[\"validation\"] = tokenized_dataset_dict[\"validation\"].map(convert_labels)\n",
    "# # tokenized_dataset_dict[\"test\"] = tokenized_dataset_dict[\"test\"].map(convert_labels)\n",
    "\n",
    "# tokenized_dataset_dict[\"train\"] = tokenized_dataset_dict[\"train\"].rename_column(\"RATING\", \"labels\")\n",
    "# tokenized_dataset_dict[\"validation\"] = tokenized_dataset_dict[\"validation\"].rename_column(\"RATING\", \"labels\")\n",
    "# tokenized_dataset_dict[\"test\"] = tokenized_dataset_dict[\"test\"].rename_column(\"RATING\", \"labels\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing_labels = tokenized_dataset_dict[\"train\"].filter(lambda x: x[\"labels\"] is None)\n",
    "# print(\"Examples with missing labels:\", missing_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train = tokenized_dataset_dict[\"train\"].to_pandas()\n",
    "# df_train['labels'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenized_dataset_dict[\"train\"].set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "# tokenized_dataset_dict[\"validation\"].set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "# tokenized_dataset_dict[\"test\"].set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.utils.data import DataLoader\n",
    "# train_dataloader = DataLoader(tokenized_dataset_dict[\"train\"], batch_size=2)\n",
    "# for batch in train_dataloader:\n",
    "#     print(batch.keys())\n",
    "#     break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "# os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:128\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define training arguments\n",
    "# training_args = TrainingArguments(\n",
    "#     output_dir=\"./results\",              # Save directory\n",
    "#     eval_strategy=\"epoch\",        # Evaluate after every epoch\n",
    "#     learning_rate=2e-5,                 # Initial learning rate\n",
    "#     per_device_train_batch_size=4,     # Batch size per device\n",
    "#     num_train_epochs=3,                 # Number of epochs\n",
    "#     weight_decay=0.01,                  # Regularization\n",
    "#     logging_dir=\"./logs\",               # Log directory\n",
    "#     save_total_limit=2,                 # Save only the last 2 checkpoints\n",
    "# )\n",
    "\n",
    "# # Initialize the Trainer\n",
    "# trainer = Trainer(\n",
    "#     model=model,                         # Your model\n",
    "#     args=training_args,                  # Training arguments\n",
    "#     train_dataset=tokenized_dataset_dict['train'],  # Training data\n",
    "#     eval_dataset=tokenized_dataset_dict['validation'],  # Validation data\n",
    "# )\n",
    "\n",
    "# # Start fine-tuning\n",
    "# trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.cuda.empty_cache()\n",
    "# print(\"Memory allocated on current device:\", torch.cuda.memory_allocated())\n",
    "# print(\"Memory reserved on current device:\", torch.cuda.memory_reserved())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # import os\n",
    "# # os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True, max_split_size_mb:128\"\n",
    "\n",
    "# from transformers import TrainingArguments, Trainer\n",
    "\n",
    "# training_args = TrainingArguments(\n",
    "#     output_dir=\"./results\",\n",
    "#     eval_strategy=\"epoch\",\n",
    "#     learning_rate=1e-5,\n",
    "#     per_device_train_batch_size=8,         # smaller batch size\n",
    "#     gradient_accumulation_steps=2,           # accumulate gradients to simulate a batch size of 4\n",
    "#     num_train_epochs=5,\n",
    "#     weight_decay=0.01,\n",
    "#     logging_dir=\"./logs\",\n",
    "#     logging_steps = 10,\n",
    "#     save_total_limit=2,\n",
    "#     fp16=False,\n",
    "#     dataloader_num_workers=4                             # enable mixed precision training\n",
    "# )\n",
    "\n",
    "# trainer = Trainer(\n",
    "#     model=model,\n",
    "#     args=training_args,\n",
    "#     train_dataset=tokenized_dataset_dict['train'],\n",
    "#     eval_dataset=tokenized_dataset_dict['validation'],\n",
    "# )\n",
    "\n",
    "# trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# labels_train = np.array([example[\"labels\"] for example in tokenized_dataset_dict[\"train\"]])\n",
    "# print(\"Min label:\", labels_train.min())\n",
    "# print(\"Max label:\", labels_train.max())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLPROJECT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
